{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d8e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from polygon import RESTClient\n",
    "from utils import view_source_code, get_dollars\n",
    "from datetime import datetime, timedelta, date\n",
    "import math, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e615b8c",
   "metadata": {},
   "source": [
    "# Testing Framework\n",
    "\n",
    "Ok so now we want to build a minimal testing framework.  This will by no means be a complete comprehensive framework, but it will be a starting point that handles what we have run across so far in a flexible way.  The goal is to create something we can build on as we come across more and more examples.  There's a few thing we need to be able to do:\n",
    "\n",
    "1. Split our data into train/val/test sets\n",
    "1. Conduct bootstrapping on a model\n",
    "1. Get metrics and statistics about test such return, p values, and others\n",
    "1. Store results and details of experiments\n",
    "\n",
    "We could just use what we did last chapter and copy that code, but we want it to be flexible.  We don't know what format data will come in and we don't know exactly what we want to do yet.  We need an easy way to accomplish what we need while keeping it easy to build unknown stuff we may need in the future.\n",
    "\n",
    ":::{note} It is very likely that if you work for a firm they will have a testing framework for you to use.  This is not meant to replace that, but by understanding how they work you will be able to effectively learn and use any framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e618603",
   "metadata": {},
   "source": [
    "### Split our Data\n",
    "\n",
    "Let's start from the beginning!  Let's say we have a dataset and we need to read in the csv and split it into train/test/valid.\n",
    "\n",
    "Let's create a `CsvGetter` class can be used to get a file from a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aba640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data')\n",
    "fpath = path/'eod-quotemedia.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1844da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvGetter:\n",
    "    def __init__(self,fpath): store_attr()\n",
    "    def __call__(self): return pd.read_csv(self.fpath, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a30aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>A</td>\n",
       "      <td>29.994186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>A</td>\n",
       "      <td>29.650137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>A</td>\n",
       "      <td>29.705185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>A</td>\n",
       "      <td>30.434568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-08</td>\n",
       "      <td>A</td>\n",
       "      <td>30.524021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-07-09</td>\n",
       "      <td>A</td>\n",
       "      <td>30.689164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker  adj_close\n",
       "0 2013-07-01      A  29.994186\n",
       "1 2013-07-02      A  29.650137\n",
       "2 2013-07-03      A  29.705185\n",
       "3 2013-07-05      A  30.434568\n",
       "4 2013-07-08      A  30.524021\n",
       "5 2013-07-09      A  30.689164"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CsvGetter(fpath)().head(6)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46694a63",
   "metadata": {},
   "source": [
    "Now that we have the csv let's create a `SizeSplitter` class to split the data based on relative sizes in a column.\n",
    "\n",
    "It's important to add in tests of inputs with good clear error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c3e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeSplitter:\n",
    "    def __init__(self,sizes=None): \n",
    "        if sizes is None:\n",
    "            self.sizes = L(('train',0.5),('valid',0.25),('test',0.25))\n",
    "        else: \n",
    "            sizes_sum = np.array([o[1] for o in sizes]).sum()\n",
    "            \n",
    "            try:test_close(sizes_sum, 1.)\n",
    "            except AssertionError: raise Exception('Your sizes must sum to 1')\n",
    "                \n",
    "            try:test_eq(['train','valid','test'],sizes.keys())\n",
    "            except AssertionError: raise Exception('You must have train, valid, and test sets')\n",
    "                \n",
    "            self.sizes = sizes\n",
    "\n",
    "        \n",
    "    def __call__(self,df):        \n",
    "        sizes = self.sizes\n",
    "        unique_dates = L(*df.date.unique()).sorted()\n",
    "\n",
    "        out = AttrDict()\n",
    "        \n",
    "        break_sz = int(len(unique_dates)*sizes[0][1])\n",
    "        out[sizes[0][0]] = df.loc[df.date <= unique_dates[break_sz]]\n",
    "        \n",
    "        _remainder_df = df.loc[df.date > unique_dates[break_sz]]\n",
    "        _remainder_dates = unique_dates[break_sz+1:]\n",
    "\n",
    "        break_sz = int(len(unique_dates)*sizes[1][1])\n",
    "        out[sizes[1][0]] = _remainder_df.loc[_remainder_df.date <= _remainder_dates[break_sz]]\n",
    "        out[sizes[2][0]] = _remainder_df.loc[_remainder_df.date > _remainder_dates[break_sz]]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9339903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CsvGetter(fpath)().head(100)\n",
    "dataset = SizeSplitter()(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235e79b",
   "metadata": {},
   "source": [
    "We can see that it's a dictionary like object with 3 sets, each of which are dataframes.  Exactly what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c377a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'valid', 'test'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2013-09-12</td>\n",
       "      <td>A</td>\n",
       "      <td>33.455318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2013-09-13</td>\n",
       "      <td>A</td>\n",
       "      <td>33.345222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker  adj_close\n",
       "51 2013-09-12      A  33.455318\n",
       "52 2013-09-13      A  33.345222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset.keys())\n",
    "display(dataset.valid.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07a8e9",
   "metadata": {},
   "source": [
    "And that's the core of it.  A getter + a splitter gives us our data splits.  Let's put that into 1 module for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a249cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule:\n",
    "    def __init__(self, getter, splitter): \n",
    "        store_attr()\n",
    "        df = getter()\n",
    "        self.datasets = splitter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5da7406d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'valid', 'test'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataModule(CsvGetter(fpath),SizeSplitter())\n",
    "dm.datasets.keys() # verify we still have our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae925c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f93cbf5",
   "metadata": {},
   "source": [
    "The nice thing is by following this same format we can define over types of getters or splitters and just pass them in for a consistent format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b7585",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6f68ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_trading_day(dte,unique_dates,dates_dict):\n",
    "    for i in range(10):\n",
    "        out = dates_dict.get(dte+timedelta(i),False) \n",
    "        if out != False: return unique_dates[out]\n",
    "    return None\n",
    "    \n",
    "class RandomModel:\n",
    "    def __init__(self,action_probs): store_attr()\n",
    "        \n",
    "    def __call__(self, df,hold_time=28):\n",
    "        out = self.open_positions(df)\n",
    "        out = self.close_positions(out,hold_time)\n",
    "        \n",
    "        f = bind(self.get_next_trading_day,unique_dates=L(*df.date))   \n",
    "        out['open_date']  = pd.to_datetime(trans.open_date.apply(f))\n",
    "        out['close_date'] = pd.to_datetime(trans.close_date.apply(f))\n",
    "        return out\n",
    "        \n",
    "    def open_positions(self,df):\n",
    "        out_cols = ['open_date','ticker','action']\n",
    "        out = pd.DataFrame(columns=out_cols)\n",
    "        in_df = df[['date','ticker']]\n",
    "        in_df.columns = out_cols[:-1]\n",
    "\n",
    "        for action,prob in action_probs.items():\n",
    "            _tmp = in_df.sample(frac=.1)\n",
    "            _tmp['action'] = action\n",
    "            out = pd.concat([out,_tmp])\n",
    "        out.sort_values('open_date',inplace=True)\n",
    "        \n",
    "        out['open_date'] = out.open_date.astype(date)\n",
    "        return out  \n",
    "    \n",
    "    def close_positions(self,df,hold_time):\n",
    "        df['close_date'] = df.open_date + timedelta(hold_time)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a1cd7",
   "metadata": {},
   "source": [
    " Now it's important to note that you should take time to optimize your code some, especially if things are running slow.  Iteration speed is critical and doing this will allow you to work faster.  At this stage you don't need to try to super optimize everything, but you should have reasonably performance code.  For example, this was the first function I wrote for `get_next_trading_day`.  It make look simpler but it's about 12 times slower!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d81fd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_trading_day_old(dte,unique_dates):\n",
    "    return unique_dates.filter(lambda x: x >= dte)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a8698847",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = L(*dm.datasets.train.date).unique().sorted()\n",
    "dates_dict = unique_dates.val2idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3fd56722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554 ms ± 4.12 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "f = bind(get_next_trading_day_old,unique_dates=unique_dates)   \n",
    "%timeit _ = dm.datasets.train.iloc[:10000].date.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6713997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.8 ms ± 528 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "f = bind(get_next_trading_day,unique_dates=unique_dates,dates_dict=dates_dict)   \n",
    "%timeit _ = dm.datasets.train.iloc[:10000].date.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3cd5882",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'action_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dm \u001b[38;5;241m=\u001b[39m DataModule(CsvGetter(fpath),SizeSplitter())\n\u001b[1;32m      2\u001b[0m h0 \u001b[38;5;241m=\u001b[39m RandomModel({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuy\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m.5\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShort\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m.1\u001b[39m})\n\u001b[0;32m----> 3\u001b[0m \u001b[43mh0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mRandomModel.__call__\u001b[0;34m(self, df, hold_time)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df,hold_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_positions(out,hold_time)\n\u001b[1;32m     15\u001b[0m     f \u001b[38;5;241m=\u001b[39m bind(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_next_trading_day,unique_dates\u001b[38;5;241m=\u001b[39mL(\u001b[38;5;241m*\u001b[39mdf\u001b[38;5;241m.\u001b[39mdate))   \n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mRandomModel.open_positions\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     23\u001b[0m in_df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     24\u001b[0m in_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m out_cols[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action,prob \u001b[38;5;129;01min\u001b[39;00m \u001b[43maction_probs\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     27\u001b[0m     _tmp \u001b[38;5;241m=\u001b[39m in_df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.1\u001b[39m)\n\u001b[1;32m     28\u001b[0m     _tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m action\n",
      "\u001b[0;31mNameError\u001b[0m: name 'action_probs' is not defined"
     ]
    }
   ],
   "source": [
    "dm = DataModule(CsvGetter(fpath),SizeSplitter())\n",
    "h0 = RandomModel({'Buy':.5,'Short':.1})\n",
    "h0(dm.datasets.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c5b53",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391c39c",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0318b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester\n",
    "    def __init__(self, data_module, metric):\n",
    "    \n",
    "    def run_bootstrap(self, h0, h1, samples, sample_size):\n",
    "        # run h0 \n",
    "        \n",
    "    \n",
    "    def plot_bootstrap(self):\n",
    "    \n",
    "    def get_results(self,last_n=3):\n",
    "        \n",
    "        return h0_mean, h1, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c66d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataModule(CsvGetter(path/'eod-quotemedia.csv'),\n",
    "                SizeSplitter())\n",
    "\n",
    "Tester(dm, h0, h1, log_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "0a828adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>action</th>\n",
       "      <th>close_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282719</th>\n",
       "      <td>2017-05-05 00:00:00</td>\n",
       "      <td>LUV</td>\n",
       "      <td>buy</td>\n",
       "      <td>2017-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144324</th>\n",
       "      <td>2013-09-05 00:00:00</td>\n",
       "      <td>DVA</td>\n",
       "      <td>buy</td>\n",
       "      <td>2013-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49148</th>\n",
       "      <td>2016-09-22 00:00:00</td>\n",
       "      <td>ARE</td>\n",
       "      <td>buy</td>\n",
       "      <td>2016-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78889</th>\n",
       "      <td>2014-08-18 00:00:00</td>\n",
       "      <td>CAT</td>\n",
       "      <td>short</td>\n",
       "      <td>2014-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>2014-12-05 00:00:00</td>\n",
       "      <td>AAL</td>\n",
       "      <td>buy</td>\n",
       "      <td>2015-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open_date ticker action close_date\n",
       "282719  2017-05-05 00:00:00    LUV    buy 2017-06-02\n",
       "144324  2013-09-05 00:00:00    DVA    buy 2013-10-03\n",
       "49148   2016-09-22 00:00:00    ARE    buy 2016-10-20\n",
       "78889   2014-08-18 00:00:00    CAT  short 2014-09-15\n",
       "1371    2014-12-05 00:00:00    AAL    buy 2015-01-02"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs = {'buy':.5,'short':.5}\n",
    "RandomModel(action_probs)(df).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell\n",
    "import shelve\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from fastcore.foundation import *\n",
    "import numpy as np\n",
    "\n",
    "# Cell\n",
    "def create(filename,keys):\n",
    "  with shelve.open(filename) as d:\n",
    "    if type(keys) == str: d[keys] = L()\n",
    "    else:\n",
    "        for key in keys: d[key] = L()\n",
    "\n",
    "# Cell\n",
    "def append(filename,new_dict,key='exp'):\n",
    "    '''Append a new_dict to list store in key - create db if needed'''\n",
    "    if not os.path.exists(filename): create(filename,key)\n",
    "    with shelve.open(filename) as d:\n",
    "        if key not in list(d.keys()): d[key] = L()\n",
    "        tmp = d[key]\n",
    "        tmp.append(new_dict)\n",
    "        d['exp'] = tmp\n",
    "\n",
    "# Cell\n",
    "def delete(filename,exp_num,key='exp'):\n",
    "    '''delete an item from list stored in key'''\n",
    "    with shelve.open(filename) as d:\n",
    "        tmp = d[key]\n",
    "        if type(exp) == int:\n",
    "            tmp.pop(exp_num)\n",
    "        if type(exp) == str:\n",
    "            for i,e in eumerate(tmp):\n",
    "              if e['name'] == name: tmp.pop(i)\n",
    "        d[key] = tmp\n",
    "\n",
    "# Cell\n",
    "def print_keys(filename,last_only=True, with_type=False, key='exp'):\n",
    "    with shelve.open(filename) as d:\n",
    "        if last_only and not with_type: print(list(d[key][-1].keys()))\n",
    "        if last_only and with_type: print({k:type(v) for k,v in d['exp'][-1].items()})\n",
    "        if not last_only and not with_type:\n",
    "            a = L()\n",
    "            for o in d['exp']: a = a + L(o.keys())\n",
    "            a = a.unique()\n",
    "            print(a)\n",
    "        if not last_only and with_type:\n",
    "            a = {}\n",
    "            for o in d['exp']: a.update({k:type(v) for k,v in o.items()})\n",
    "            print(a)\n",
    "\n",
    "# Cell\n",
    "def get_stat(filename,exp_num,stat,key='exp',display=True):\n",
    "    '''get a specific stat (ie loss) from key for a given expirament\n",
    "    Goes well with partial\n",
    "    '''\n",
    "    with shelve.open(filename) as d:\n",
    "      if display: print(f'd[{key}][{exp_num}][{stat}]: {d[key][exp_num][stat]}')\n",
    "      return (f'd[{key}][{exp_num}][{stat}]',d[key][exp_num][stat])\n",
    "\n",
    "# Cell\n",
    "def get_stats(filename,exp_num,stats,key='exp',display=True):\n",
    "    return [get_stat(filename,exp_num,stat,key,display) for stat in stats]\n",
    "\n",
    "# Cell\n",
    "def print_best(filename,stat,best='min', key='exp'):\n",
    "    with shelve.open(filename) as d: exps = len(d[key])\n",
    "    if best == 'min':\n",
    "        out = (np.inf,None)\n",
    "        for i in range(exps):\n",
    "          a,b = get_stat(filename,i,stat,display=False)\n",
    "          if min(b) < out[0]: out = (min(b),i)\n",
    "    if best == 'max':\n",
    "        out = (-np.inf,None)\n",
    "        for i in range(exps):\n",
    "          a,b = get_stat(filename,i,stat,display=False)\n",
    "          if max(b) > out[0]: out = (max(b),i)\n",
    "\n",
    "    print(f'{stat} {best} value = {out[0]} | best idx = {out[1]-exps}')\n",
    "\n",
    "# Cell\n",
    "def graph_stat(filename,stat,idxs=[-1,-2,-3], key='exp',name='name',figsize=(12,6)):\n",
    "    with shelve.open(filename) as d:\n",
    "        fig,ax = plt.subplots(figsize=figsize)\n",
    "        for e in L(d[key])[idxs]:\n",
    "            try:\n",
    "              vals = e[stat]\n",
    "              ax.plot(range(len(e[stat])),e[stat],label=e[name])\n",
    "              ax.legend();ax.set_title(f'{stat}')\n",
    "            except:\n",
    "              print(f'Unable to plot {stat} for {e[name]}')\n",
    "\n",
    "def graph_stats(filename,stats,idxs=[-1,-2,-3],key='exp',name='name',figsize=(12,6)):\n",
    "    for stat in stats:\n",
    "        graph_stat(filename,stat,idxs,key,name,figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57cb589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
